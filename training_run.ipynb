{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "082cb18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /home/giuseppe_bonomo/RatioWaveNet2\n",
      "Configs YAML: ['eegnet.yaml', 'ctnet.yaml', 'atcnet.yaml', 'ratiowavenet.yaml', 'tsseffnet.yaml', 'tcformer.yaml', 'basenet.yaml', 'mscformer.yaml', 'eegconformer.yaml', 'shallownet.yaml', 'eegtcnet.yaml']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import os, sys, yaml, time, glob, re, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown, Image\n",
    "\n",
    "# --- Imposta qui la cartella che contiene 'train_pipeline.py' ---\n",
    "PROJECT_ROOT = Path.cwd()  # es. Path(\"/home/giuseppe_bonomo/RatioWaveNet2\")\n",
    "if not (PROJECT_ROOT / \"train_pipeline.py\").exists():\n",
    "    print(\"'train_pipeline.py' non trovato nella dir corrente. Provo in quella superiore...\")\n",
    "    if (PROJECT_ROOT.parent / \"train_pipeline.py\").exists():\n",
    "        PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Imposta PROJECT_ROOT alla cartella del repo (con train_pipeline.py)\")\n",
    "\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"Configs YAML:\", [p.name for p in (PROJECT_ROOT / \"configs\").glob(\"*.yaml\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51c7a930",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===================== PARAMETRI ESPERIMENTO =====================\n",
    "MODEL_NAME   = \"ratiowavenet\"        # es. \"tcformer\", \"atcnet\", \"eegnet\", \"ratiowavenet\", ...\n",
    "DATASET      = \"bcic2a\"          # \"bcic2a\", \"bcic2b\", \"hgd\", \"reh_mi\", \"bcic3\"\n",
    "USE_LOSO     = False             # True=LOSO, False=intra-soggetto\n",
    "INTERAUG     = None              # True / False / None (usa default da YAML)\n",
    "GPU_ID       = 0                 # -1 per CPU; 0/1/... per GPU\n",
    "SEED_LIST    = [0,1,2,3,4]       # Elenco seed da lanciare in sequenza\n",
    "SEED_SLEEP_S = 2                 # Pausa tra seed (secondi)\n",
    "\n",
    "SUBJECT_MODE = \"one\"             # \"all\" | \"one\" | \"list\"\n",
    "ONE_SUBJECT  = 6\n",
    "SUBJECT_LIST = [1,2,3]\n",
    "\n",
    "VERBOSE_TRAIN        = True\n",
    "PLOT_CM_PER_SUBJECT  = True\n",
    "PLOT_CM_AVERAGE      = True\n",
    "SAVE_CHECKPOINTS     = False\n",
    "\n",
    "OVERRIDE_MAX_EPOCHS  = None\n",
    "# =================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cdbacab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow not install, you could not use those pipelines\n",
      "🔧 Trainer patch applicata (toggle progress bar).\n",
      "✅ Config base pronta\n",
      "dataset_name: bcic2a\n",
      "subject_ids: 6\n",
      "max_epochs: 1000\n",
      "max_epochs_2b: 500\n",
      "max_epochs_loso: 125\n",
      "max_epochs_loso_hgd: 77\n",
      "seed: 0\n",
      "z_scale: true\n",
      "preprocessing:\n",
      "  sfreq: 250\n",
      "  low_cut: null\n",
      "  high_cut: null\n",
      "  start: 0.0\n",
      "  stop: 0.0\n",
      "  batch_size: 32\n",
      "  z_scale: true\n",
      "  interaug: true\n",
      "model: RatioWaveNet\n",
      "model_kwargs:\n",
      "  F1: 32\n",
      "  temp_kernel_lengths:\n",
      "  - 20\n",
      "  - 32\n",
      "  - 64\n",
      "  d_group: 16\n",
      "  D: 2\n",
      "  pool_length_1: 8\n",
      "  pool_length_2: 7\n",
      "  dropout_conv: 0.4\n",
      "  use_group_attn: true\n",
      "  q_heads: 4\n",
      "  kv_heads: 2\n",
      "  trans_depth: 5\n",
      "  trans_dropout: 0.4\n",
      "  tcn_depth: 2\n",
      "  kernel_length_tcn: 4\n",
      "  dropout_tcn: 0.3\n",
      "  lr: 0.0009\n",
      "  beta_1: 0.5\n",
      "  weight_decay: 0.001\n",
      "  optimizer: adam\n",
      "  scheduler: true\n",
      "  warmup_epochs: 20\n",
      "  warmup_epochs_loso: 3\n",
      "  use_rdwt: true\n",
      "  rdwt_levels: 4\n",
      "  rdwt_level_choices:\n",
      "  - 2\n",
      "  - 3\n",
      "  - 4\n",
      "  - 5\n",
      "  - 6\n",
      "  rdwt_base_kernel_len: 16\n",
      "  rdwt_init_dilations:\n",
      "  - 1.5\n",
      "  - 1.6667\n",
      "  - 1.75\n",
      "  - 1.8\n",
      "  - 1.8333\n",
      "  - 1.8571\n",
      "  rdwt_soft_threshold: true\n",
      "  rdwt_threshold_init: 0.0\n",
      "  rdwt_max_scale: 4.0\n",
      "  rdwt_l2_on_logscale: 0.0\n",
      "  rdwt_use_spread_loss: false\n",
      "  rdwt_spread_lambda: 3e-3\n",
      "  rdwt_spread_gamma: 5.0\n",
      "  rdwt_temp_init: 0.8\n",
      "gpu_id: 0\n",
      "plot_cm_per_subject: true\n",
      "plot_cm_average: true\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Costruisce una CONFIG base (senza seed), replicando la logica in run()\n",
    "from train_pipeline import train_and_test\n",
    "import pytorch_lightning as pl\n",
    "from functools import wraps\n",
    "from pytorch_lightning.trainer.trainer import Trainer as _PLTrainer\n",
    "\n",
    "CONFIG_DIR = PROJECT_ROOT / \"configs\"\n",
    "config_path = CONFIG_DIR / f\"{MODEL_NAME}.yaml\"\n",
    "assert config_path.exists(), f\"Config non trovato: {config_path}\"\n",
    "\n",
    "with open(config_path) as f:\n",
    "    base_cfg = yaml.safe_load(f)\n",
    "\n",
    "cfg = dict(base_cfg)\n",
    "if USE_LOSO:\n",
    "    cfg[\"dataset_name\"] = f\"{DATASET}_loso\"\n",
    "    cfg[\"max_epochs\"]   = cfg[\"max_epochs_loso_hgd\"] if DATASET == \"hgd\" else cfg[\"max_epochs_loso\"]\n",
    "    if \"model_kwargs\" in cfg and \"warmup_epochs_loso\" in cfg[\"model_kwargs\"]:\n",
    "        cfg[\"model_kwargs\"][\"warmup_epochs\"] = cfg[\"model_kwargs\"][\"warmup_epochs_loso\"]\n",
    "else:\n",
    "    cfg[\"dataset_name\"] = DATASET\n",
    "    cfg[\"max_epochs\"]   = cfg[\"max_epochs_2b\"] if DATASET == \"bcic2b\" else cfg[\"max_epochs\"]\n",
    "\n",
    "cfg[\"preprocessing\"] = cfg[\"preprocessing\"][DATASET]\n",
    "cfg[\"preprocessing\"][\"z_scale\"] = cfg.get(\"z_scale\", cfg[\"preprocessing\"].get(\"z_scale\", False))\n",
    "\n",
    "if INTERAUG is True:\n",
    "    cfg[\"preprocessing\"][\"interaug\"] = True\n",
    "elif INTERAUG is False:\n",
    "    cfg[\"preprocessing\"][\"interaug\"] = False\n",
    "else:\n",
    "    cfg[\"preprocessing\"][\"interaug\"] = cfg.get(\"interaug\", cfg[\"preprocessing\"].get(\"interaug\", False))\n",
    "cfg.pop(\"interaug\", None)\n",
    "\n",
    "if SUBJECT_MODE == \"all\":\n",
    "    cfg[\"subject_ids\"] = \"all\"\n",
    "elif SUBJECT_MODE == \"one\":\n",
    "    cfg[\"subject_ids\"] = ONE_SUBJECT\n",
    "elif SUBJECT_MODE == \"list\":\n",
    "    cfg[\"subject_ids\"] = SUBJECT_LIST\n",
    "else:\n",
    "    raise ValueError(\"SUBJECT_MODE deve essere 'all' | 'one' | 'list'\")\n",
    "\n",
    "cfg[\"gpu_id\"] = GPU_ID\n",
    "cfg[\"plot_cm_per_subject\"] = bool(PLOT_CM_PER_SUBJECT)\n",
    "cfg[\"plot_cm_average\"]     = bool(PLOT_CM_AVERAGE)\n",
    "if SAVE_CHECKPOINTS:\n",
    "    cfg[\"save_checkpoint\"] = True\n",
    "\n",
    "if OVERRIDE_MAX_EPOCHS is not None:\n",
    "    cfg[\"max_epochs\"] = int(OVERRIDE_MAX_EPOCHS)\n",
    "\n",
    "os.environ[\"PL_TRAIN_PROGRESS_BAR\"] = \"1\" if VERBOSE_TRAIN else \"0\"\n",
    "if not hasattr(_PLTrainer, \"_patched_progress_bar\"):\n",
    "    _orig_init = _PLTrainer.__init__\n",
    "    @wraps(_orig_init)\n",
    "    def _wrapped_init(self, *args, **kwargs):\n",
    "        kwargs.setdefault(\"enable_progress_bar\", (os.environ.get(\"PL_TRAIN_PROGRESS_BAR\",\"1\") == \"1\"))\n",
    "        kwargs.setdefault(\"enable_model_summary\", False)\n",
    "        kwargs.setdefault(\"log_every_n_steps\", 1)\n",
    "        return _orig_init(self, *args, **kwargs)\n",
    "    _PLTrainer.__init__ = _wrapped_init\n",
    "    _PLTrainer._patched_progress_bar = True\n",
    "    print(\"🔧 Trainer patch applicata (toggle progress bar).\")\n",
    "\n",
    "print(\"✅ Config base pronta\")\n",
    "print(yaml.dump(cfg, sort_keys=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c0f598c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Patch write_summary attivata → verrà creato 'results.txt' in ogni run.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Patch write_summary per creare 'results.txt' compatibile\n",
    "from utils import metrics as _metrics_mod\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "if not hasattr(_metrics_mod, \"_write_summary_patched\"):\n",
    "    _orig_write_summary = _metrics_mod.write_summary\n",
    "\n",
    "    def write_results_txt(result_dir, model_name, dataset_name, subject_ids, param_count,\n",
    "                          test_accs, test_losses, test_kappas, train_times, test_times, response_times):\n",
    "        result_dir = Path(result_dir)\n",
    "        lines = []\n",
    "        lines.append(f\"#Params: {param_count}\")\n",
    "        if isinstance(subject_ids, (list, tuple)):\n",
    "            for sid, acc in zip(subject_ids, test_accs):\n",
    "                try:\n",
    "                    sid_int = int(sid)\n",
    "                except Exception:\n",
    "                    sid_int = sid\n",
    "                lines.append(f\"Subject {sid_int} => Test Acc: {float(acc):.4f}\")\n",
    "        if len(test_accs):\n",
    "            lines.append(f\"Average Test Accuracy: {np.mean(test_accs):.4f} ± {np.std(test_accs):.4f}\")\n",
    "        if len(test_kappas):\n",
    "            lines.append(f\"Average Test Kappa: {np.mean(test_kappas):.4f} ± {np.std(test_kappas):.4f}\")\n",
    "        (result_dir / \"results.txt\").write_text(\"\\n\".join(lines))\n",
    "\n",
    "    def _patched_write_summary(result_dir, model_name, dataset_name, subject_ids, param_count,\n",
    "                               test_accs, test_losses, test_kappas, train_times, test_times, response_times):\n",
    "        _orig_write_summary(result_dir, model_name, dataset_name, subject_ids, param_count,\n",
    "                            test_accs, test_losses, test_kappas, train_times, test_times, response_times)\n",
    "        write_results_txt(result_dir, model_name, dataset_name, subject_ids, param_count,\n",
    "                          test_accs, test_losses, test_kappas, train_times, test_times, response_times)\n",
    "\n",
    "    _metrics_mod.write_summary = _patched_write_summary\n",
    "    _metrics_mod._write_summary_patched = True\n",
    "    print(\"📝 Patch write_summary attivata → verrà creato 'results.txt' in ogni run.\")\n",
    "else:\n",
    "    print(\"ℹ️ Patch write_summary già attiva.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9498bed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Avvio multi-seed: [0, 1, 2, 3, 4]\n",
      "\n",
      "==================== Seed 0 ====================\n",
      "\n",
      ">>> Training on subject: 6\n",
      "Setting all random seeds to 0, cuda_available=True\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m==================== Seed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msd\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ====================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mtrain_and_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_cfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_cfg\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39mMODEL_NAME)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_seed-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msd\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_*\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m candidates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(results_root\u001b[38;5;241m.\u001b[39mglob(pattern), key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mgetmtime)\n",
      "File \u001b[0;32m~/RatioWaveNet2/train_pipeline.py:97\u001b[0m, in \u001b[0;36mtrain_and_test\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# ---------------- TRAIN ----------------\u001b[39;00m\n\u001b[1;32m     96\u001b[0m st_train \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 97\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatamodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m train_times\u001b[38;5;241m.\u001b[39mappend((time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m st_train) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m) \u001b[38;5;66;03m# minutes\u001b[39;00m\n\u001b[1;32m    100\u001b[0m rdwt_summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrdwt_summary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tcformer310/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:532\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m    531\u001b[0m _verify_strategy_supports_compile(model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy)\n\u001b[0;32m--> 532\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tcformer310/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:43\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     46\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/miniconda3/envs/tcformer310/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:571\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_connector\u001b[38;5;241m.\u001b[39mattach_data(\n\u001b[1;32m    562\u001b[0m     model, train_dataloaders\u001b[38;5;241m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[38;5;241m=\u001b[39mval_dataloaders, datamodule\u001b[38;5;241m=\u001b[39mdatamodule\n\u001b[1;32m    563\u001b[0m )\n\u001b[1;32m    565\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    567\u001b[0m     ckpt_path,\n\u001b[1;32m    568\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    569\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    570\u001b[0m )\n\u001b[0;32m--> 571\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tcformer310/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:956\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger_connector\u001b[38;5;241m.\u001b[39mreset_metrics()\n\u001b[1;32m    955\u001b[0m \u001b[38;5;66;03m# strategy will configure model and move it to the device\u001b[39;00m\n\u001b[0;32m--> 956\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;66;03m# hook\u001b[39;00m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;241m==\u001b[39m TrainerFn\u001b[38;5;241m.\u001b[39mFITTING:\n",
      "File \u001b[0;32m~/miniconda3/envs/tcformer310/lib/python3.10/site-packages/pytorch_lightning/strategies/single_device.py:75\u001b[0m, in \u001b[0;36mSingleDeviceStrategy.setup\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msetup\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer: pl\u001b[38;5;241m.\u001b[39mTrainer) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msetup(trainer)\n",
      "File \u001b[0;32m~/miniconda3/envs/tcformer310/lib/python3.10/site-packages/pytorch_lightning/strategies/single_device.py:72\u001b[0m, in \u001b[0;36mSingleDeviceStrategy.model_to_device\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmodel_to_device\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself.model must be set before self.model.to()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tcformer310/lib/python3.10/site-packages/lightning_fabric/utilities/device_dtype_mixin.py:54\u001b[0m, in \u001b[0;36m_DeviceDtypeModuleMixin.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m device, dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39m_parse_to(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__update_properties(device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tcformer310/lib/python3.10/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tcformer310/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tcformer310/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 797 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/tcformer310/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tcformer310/lib/python3.10/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/miniconda3/envs/tcformer310/lib/python3.10/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Multi-seed loop\n",
    "from datetime import datetime\n",
    "\n",
    "results_root = PROJECT_ROOT / \"results\"\n",
    "seed_to_dir = {}\n",
    "\n",
    "print(\"🚀 Avvio multi-seed:\", SEED_LIST)\n",
    "for sd in SEED_LIST:\n",
    "    run_cfg = dict(cfg)\n",
    "    run_cfg[\"seed\"] = int(sd)\n",
    "    start = time.time()\n",
    "    print(f\"\\n==================== Seed {sd} ====================\")\n",
    "    train_and_test(run_cfg)\n",
    "    pattern = f\"{run_cfg.get('model', MODEL_NAME)}_{run_cfg['dataset_name']}_seed-{sd}_*\"\n",
    "    candidates = sorted(results_root.glob(pattern), key=os.path.getmtime)\n",
    "    if not candidates:\n",
    "        candidates = sorted(results_root.glob(f\"*{run_cfg['dataset_name']}*seed-{sd}*\"), key=os.path.getmtime)\n",
    "    latest = candidates[-1] if candidates else None\n",
    "    seed_to_dir[sd] = latest\n",
    "    print(f\"✅ Seed {sd} completato. Dir: {latest}\")\n",
    "    time.sleep(SEED_SLEEP_S)\n",
    "\n",
    "print(\"📂 seed_to_dir:\", seed_to_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcformer310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
